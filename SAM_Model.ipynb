{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import io\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Changable parameters ### Remember to change tilt and packing density\n",
    "samPath = '/Users/jacky/Documents/py3samsdk-master'\n",
    "path_to_csv = 'csvs/'\n",
    "\n",
    "year = 2013\n",
    "description = 'tilted' # set a description of of this data set (e.g. flush, tilted)\n",
    "add_to_existing = True # if True, will add on to existing hourly.csv and yearly.csv files\n",
    "############################\n",
    "# Remember to change tilt and packing density below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if samPath not in sys.path:\n",
    "    sys.path.insert(0, samPath)\n",
    "from py3samsdk.sscapi import PySSC\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "ssc_lib = '/Applications/sdk-release/osx64/'  # path to SAM SSC Library\n",
    "ssc = PySSC(ssc_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = pd.read_csv(\"sunroof_data/project-sunroof-postal_code-11292017.csv\").loc[:,['region_name', 'state_name',  'lat_avg', 'percent_covered', 'lng_avg', 'number_of_panels_f', 'number_of_panels_total', 'yearly_sunlight_kwh_f']]\n",
    "zipcodes['capacity'] = zipcodes['number_of_panels_f']*0.00025\n",
    "zipcodes['region_name'] = zipcodes['region_name'].apply(lambda x: str(x)[:-2])\n",
    "\n",
    "# Set number to threshold that we want for percent_covered\n",
    "zipcodes = zipcodes[zipcodes['percent_covered'] >= 80]\n",
    "zipcodes = zipcodes[zipcodes['state_name'] != 'Alaska'] # NSRDB does not have weather data for most of Alaska\n",
    "latlon = zipcodes.reset_index()\n",
    "latlon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# info should describe the data (e.g. tilted roof, flat roof)\n",
    "def create_hourly_csv(df, year, info):\n",
    "    if info != '':\n",
    "        info = '_' + info\n",
    "    if not os.path.isfile('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info)):\n",
    "        df.to_csv('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info))\n",
    "    else:\n",
    "        df.to_csv('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info), mode='a', header=False)\n",
    "#         # append a number at the end of the filename to prevent overwritting existing files with the same name\n",
    "#         i = 1\n",
    "#         while os.path.isfile('csvs/agg_years/hourly{year}{info}({index}).csv'.format(year = year, info = info, index=i)):\n",
    "#             i += 1\n",
    "#         df.to_csv('csvs/agg_years/hourly{year}{info}({index}).csv'.format(year = year, info = info, index=i))\n",
    "\n",
    "\n",
    "def create_yearly_csv(df, year, info):\n",
    "    if info != '':\n",
    "        info = '_' + info\n",
    "#     if not os.path.isfile('csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info)):\n",
    "    df.to_csv('csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info))\n",
    "#     else:\n",
    "#         # append a number at the end of the filename to prevent overwritting existing files with the same name\n",
    "#         i = 1\n",
    "#         while os.path.isfile('csvs/agg_years/yearly{year}{info}({index}).csv'.format(year = year, info = info, index=i)):\n",
    "#             i += 1\n",
    "#         df.to_csv('csvs/agg_years/yearly{year}{info}({index}).csv'.format(year = year, info = info, index=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_tables():\n",
    "    interval = '60'\n",
    "    if description != '':\n",
    "        info = '_' + description\n",
    "    path_to_yearly = 'csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info)\n",
    "    path_to_hourly = 'csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info)\n",
    "\n",
    "    hourly_df = pd.DataFrame(index = pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "    hourly_df.columns.name = None\n",
    "    hourly_df_zipcodes = []\n",
    "    if os.path.isfile(path_to_yearly) and os.path.isfile(path_to_hourly):\n",
    "        print(\"Reading existing files for {year}{info}\".format(year = year, info = info))\n",
    "        yearly_generations = pd.read_csv(path_to_yearly).set_index('region_name')['generations']\n",
    "        yearly_generations.index = yearly_generations.index.astype(str) # zipcode indices are interpreted as int, but we want str\n",
    "        hourly_df_zipcodes = pd.read_csv(path_to_hourly, index_col=0).index.astype(str)\n",
    "#         hourly_df = hourly_df.T\n",
    "        \n",
    "    else:\n",
    "        print(\"New tables will be generated\")\n",
    "        yearly_generations = pd.Series(np.nan, index = latlon['region_name'])\n",
    "        \n",
    "    return yearly_generations, hourly_df, hourly_df_zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_sam():\n",
    "\n",
    "    interval = '60'\n",
    "\n",
    "    # Run weather data through SAM\n",
    "    for index, row in latlon.iterrows():\n",
    "        if not np.isnan(yearly_generations.loc[row['region_name']]) and row['region_name'] in existing_zipcodes_hourly:\n",
    "            continue\n",
    "\n",
    "        if os.path.isfile('{path}{year}/{region}_{state}.csv'.format(path=path_to_csv, year=year, region=row['region_name'], state=row['state_name'])):\n",
    "            data = pd.read_csv('{path}{year}/{region}_{state}.csv'.format(path=path_to_csv, year=year, region=row['region_name'], state=row['state_name']))\n",
    "        else:\n",
    "            print(\"No weather data for \" + row['region_name'])\n",
    "            continue\n",
    "\n",
    "        lat = row['lat_avg']\n",
    "        lon = row['lng_avg']\n",
    "        capacity = row['capacity']\n",
    "        metadata = data.iloc[0:1, :]\n",
    "\n",
    "        timezone = metadata['Time Zone'].values[0]\n",
    "        elevation = metadata['Elevation'].values[0]\n",
    "\n",
    "        # omit metadata at the top (hence the 2:)\n",
    "        loc_data = data.iloc[:,:]\n",
    "        loc_data.columns = loc_data.iloc[1] # reassign column names to the ones in the first row of the old table\n",
    "        loc_data = loc_data.iloc[2:, :]\n",
    "        loc_data = loc_data.set_index(pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "        loc_data = loc_data.dropna(axis = 1, how='all')\n",
    "        loc_data[['DNI','DHI', 'Wind Speed', 'Temperature']] = loc_data[['DNI','DHI', 'Wind Speed', 'Temperature']].apply(pd.to_numeric)\n",
    "\n",
    "        wfd = ssc.data_create()\n",
    "        ssc.data_set_number(wfd, 'lat', lat)\n",
    "        ssc.data_set_number(wfd, 'lon', lon)\n",
    "        ssc.data_set_number(wfd, 'tz', float(timezone))\n",
    "        ssc.data_set_number(wfd, 'elev', float(elevation))\n",
    "        ssc.data_set_array(wfd, 'year', loc_data.index.year)\n",
    "        ssc.data_set_array(wfd, 'month', loc_data.index.month)\n",
    "        ssc.data_set_array(wfd, 'day', loc_data.index.day)\n",
    "        ssc.data_set_array(wfd, 'hour', loc_data.index.hour)\n",
    "        ssc.data_set_array(wfd, 'minute', loc_data.index.minute)\n",
    "        ssc.data_set_array(wfd, 'dn', loc_data['DNI'])\n",
    "        ssc.data_set_array(wfd, 'df', loc_data['DHI'])\n",
    "        ssc.data_set_array(wfd, 'wspd', loc_data['Wind Speed'])\n",
    "        ssc.data_set_array(wfd, 'tdry', loc_data['Temperature'])\n",
    "\n",
    "        # Create SAM compliant object  \n",
    "        dat = ssc.data_create()\n",
    "        ssc.data_set_table(dat, 'solar_resource_data', wfd)\n",
    "        ssc.data_free(wfd)\n",
    "\n",
    "        # Specify the system Configuration\n",
    "        # Set system capacity in MW\n",
    "        system_capacity = capacity\n",
    "        ssc.data_set_number(dat, 'system_capacity', system_capacity)\n",
    "        # Set DC/AC ratio (or power ratio). See https://sam.nrel.gov/sites/default/files/content/virtual_conf_july_2013/07-sam-virtual-conference-2013-woodcock.pdf\n",
    "        ssc.data_set_number(dat, 'dc_ac_ratio', 1.15)\n",
    "        # Set tilt of system in degrees\n",
    "        # For Google data, roof segments are considered Flat for roofs with a tilt of less than 10%\n",
    "        ssc.data_set_number(dat, 'tilt', lat) ####tilt\n",
    "        # Set azimuth angle (in degrees) from north (0 degrees)\n",
    "        ssc.data_set_number(dat, 'azimuth', 180)\n",
    "        # Set the inverter efficency\n",
    "        ssc.data_set_number(dat, 'inv_eff', 96)\n",
    "        # Set the system losses, in percent\n",
    "        ssc.data_set_number(dat, 'losses', 14.0757)\n",
    "        # Specify fixed tilt system (0=Fixed, 1=Fixed Roof, 2=1 Axis Tracker, 3=Backtracted, 4=2 Axis Tracker)\n",
    "        ssc.data_set_number(dat, 'array_type', 0)\n",
    "        # Set ground coverage ratio (PACKING DENSITY)\n",
    "        ssc.data_set_number(dat, 'gcr', (np.cos(np.radians(lat)))**2) ####Packing Density\n",
    "        # Set constant loss adjustment\n",
    "        ssc.data_set_number(dat, 'adjust:constant', 0)\n",
    "\n",
    "        # execute and put generation results back into dataframe\n",
    "        mod = ssc.module_create('pvwattsv5')\n",
    "        ssc.module_exec(mod, dat)\n",
    "        loc_data['generation'] = np.array(ssc.data_get_array(dat, 'gen'))\n",
    "        hourly_df.loc[:, row['region_name']] = loc_data['generation'] # column of generation data from SAM model\n",
    "        # free the memory\n",
    "        ssc.data_free(dat)\n",
    "        ssc.module_free(mod)\n",
    "        sys.stdout.write('\\r{0}. {1}: {2}'.format(index, row['region_name'], loc_data['generation'].sum()))\n",
    "        sys.stdout.flush()\n",
    "        yearly_generations[row['region_name']] = loc_data['generation'].sum()*1000\n",
    "        \n",
    "    # latlon['generations'] = yearly_generations\n",
    "    # latlon['error codes'] = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to start the program\n",
    "try:\n",
    "    yearly_generations, hourly_df, existing_zipcodes_hourly = instantiate_tables()\n",
    "    run_sam()\n",
    "    output_yearly = latlon.set_index('region_name')\n",
    "    output_yearly['generations'] = yearly_generations\n",
    "    create_hourly_csv(hourly_df.T, year, description)\n",
    "    create_yearly_csv(output_yearly, year, description)\n",
    "except (KeyboardInterrupt, Exception) as e:\n",
    "    print()\n",
    "    print(e)\n",
    "    print(\"Closing. Saving current progress...\")\n",
    "    output_yearly = latlon.set_index('region_name')\n",
    "    output_yearly['generations'] = yearly_generations\n",
    "    \n",
    "    create_hourly_csv(hourly_df.T, year, description)\n",
    "    create_yearly_csv(output_yearly, year, description)\n",
    "    print(\"Saved\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
