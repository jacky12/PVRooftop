{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import io\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Changable parameters ### Remember to change tilt and packing density\n",
    "samPath = '/Users/jacky/Documents/py3samsdk-master'\n",
    "path_to_csv = 'csvs/'\n",
    "\n",
    "year = 2014\n",
    "description = 'flush' # set a description of of this data set (e.g. flush, tilted)\n",
    "add_to_existing = True # if True, will add on to existing hourly.csv and yearly.csv files\n",
    "############################\n",
    "# Remember to change tilt and packing density below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if samPath not in sys.path:\n",
    "    sys.path.insert(0, samPath)\n",
    "from py3samsdk.sscapi import PySSC\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "ssc_lib = '/Applications/sdk-release/osx64/'  # path to SAM SSC Library\n",
    "ssc = PySSC(ssc_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>region_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>lat_avg</th>\n",
       "      <th>percent_covered</th>\n",
       "      <th>lng_avg</th>\n",
       "      <th>number_of_panels_f</th>\n",
       "      <th>number_of_panels_total</th>\n",
       "      <th>yearly_sunlight_kwh_f</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15104</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.406255</td>\n",
       "      <td>98.791687</td>\n",
       "      <td>-79.862353</td>\n",
       "      <td>42634</td>\n",
       "      <td>130282.0</td>\n",
       "      <td>1.202862e+07</td>\n",
       "      <td>10.65850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>15108</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.505561</td>\n",
       "      <td>96.886620</td>\n",
       "      <td>-80.187328</td>\n",
       "      <td>397143</td>\n",
       "      <td>863308.0</td>\n",
       "      <td>1.132624e+08</td>\n",
       "      <td>99.28575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>15106</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.404535</td>\n",
       "      <td>99.683730</td>\n",
       "      <td>-80.094418</td>\n",
       "      <td>133591</td>\n",
       "      <td>350858.0</td>\n",
       "      <td>3.820641e+07</td>\n",
       "      <td>33.39775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>15112</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.404671</td>\n",
       "      <td>99.732083</td>\n",
       "      <td>-79.839290</td>\n",
       "      <td>12877</td>\n",
       "      <td>44229.0</td>\n",
       "      <td>3.605938e+06</td>\n",
       "      <td>3.21925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>15110</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>40.370982</td>\n",
       "      <td>99.574633</td>\n",
       "      <td>-79.852884</td>\n",
       "      <td>38592</td>\n",
       "      <td>73782.0</td>\n",
       "      <td>1.103744e+07</td>\n",
       "      <td>9.64800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index region_name    state_name    lat_avg  percent_covered    lng_avg  \\\n",
       "0      1       15104  Pennsylvania  40.406255        98.791687 -79.862353   \n",
       "1      3       15108  Pennsylvania  40.505561        96.886620 -80.187328   \n",
       "2      4       15106  Pennsylvania  40.404535        99.683730 -80.094418   \n",
       "3      5       15112  Pennsylvania  40.404671        99.732083 -79.839290   \n",
       "4      6       15110  Pennsylvania  40.370982        99.574633 -79.852884   \n",
       "\n",
       "   number_of_panels_f  number_of_panels_total  yearly_sunlight_kwh_f  capacity  \n",
       "0               42634                130282.0           1.202862e+07  10.65850  \n",
       "1              397143                863308.0           1.132624e+08  99.28575  \n",
       "2              133591                350858.0           3.820641e+07  33.39775  \n",
       "3               12877                 44229.0           3.605938e+06   3.21925  \n",
       "4               38592                 73782.0           1.103744e+07   9.64800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcodes = pd.read_csv(\"sunroof_data/project-sunroof-postal_code-11292017.csv\").loc[:,['region_name', 'state_name',  'lat_avg', 'percent_covered', 'lng_avg', 'number_of_panels_f', 'number_of_panels_total', 'yearly_sunlight_kwh_f']]\n",
    "zipcodes['capacity'] = zipcodes['number_of_panels_f']*0.00025 # Google assumes each panel is 250W and we want capacity in MW\n",
    "zipcodes['region_name'] = zipcodes['region_name'].apply(lambda x: str(x)[:-2])\n",
    "\n",
    "# Set number to threshold that we want for percent_covered\n",
    "zipcodes = zipcodes[zipcodes['percent_covered'] >= 80]\n",
    "zipcodes = zipcodes[zipcodes['state_name'] != 'Alaska'] # NSRDB does not have weather data for most of Alaska\n",
    "latlon = zipcodes.reset_index()\n",
    "latlon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degrees_tilt_n</th>\n",
       "      <th>degrees_tilt_e</th>\n",
       "      <th>degrees_tilt_s</th>\n",
       "      <th>degrees_tilt_w</th>\n",
       "      <th>degrees_tilt_f</th>\n",
       "      <th>install_size_kw_buckets_json</th>\n",
       "      <th>install_size_kw_buckets_n_json</th>\n",
       "      <th>install_size_kw_buckets_e_json</th>\n",
       "      <th>install_size_kw_buckets_s_json</th>\n",
       "      <th>install_size_kw_buckets_w_json</th>\n",
       "      <th>install_size_kw_buckets_f_json</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>18.057999</td>\n",
       "      <td>26.270523</td>\n",
       "      <td>27.476409</td>\n",
       "      <td>25.391170</td>\n",
       "      <td>2.931321</td>\n",
       "      <td>[[0,1134],[5,1720],[10,774],[15,334],[20,136],...</td>\n",
       "      <td>[[0,283],[5,51],[10,12],[15,4],[20,3],[25,3],[...</td>\n",
       "      <td>[[0,1200],[5,597],[10,163],[15,44],[20,28],[25...</td>\n",
       "      <td>[[0,1389],[5,1195],[10,243],[15,45],[20,32],[2...</td>\n",
       "      <td>[[0,1045],[5,521],[10,142],[15,36],[20,30],[25...</td>\n",
       "      <td>[[0,212],[5,77],[10,33],[15,25],[20,19],[25,15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>17.444525</td>\n",
       "      <td>25.881517</td>\n",
       "      <td>28.781245</td>\n",
       "      <td>26.197519</td>\n",
       "      <td>2.940489</td>\n",
       "      <td>[[0,550],[5,552],[10,265],[15,146],[20,95],[25...</td>\n",
       "      <td>[[0,123],[5,33],[10,10],[15,9],[20,3],[25,5],[...</td>\n",
       "      <td>[[0,463],[5,201],[10,62],[15,23],[20,19],[25,1...</td>\n",
       "      <td>[[0,562],[5,336],[10,134],[15,62],[20,34],[25,...</td>\n",
       "      <td>[[0,483],[5,206],[10,75],[15,40],[20,22],[25,1...</td>\n",
       "      <td>[[0,117],[5,51],[10,16],[15,12],[20,16],[25,17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>17.607019</td>\n",
       "      <td>24.261329</td>\n",
       "      <td>31.431343</td>\n",
       "      <td>28.438918</td>\n",
       "      <td>1.980439</td>\n",
       "      <td>[[0,5],[5,4],[10,2],[15,6],[20,2],[25,4],[30,1...</td>\n",
       "      <td>[[0,4],[5,2],[15,1],[25,1],[35,1],[40,1],[45,1]]</td>\n",
       "      <td>[[0,8],[5,8],[10,6],[15,6],[20,2],[25,1],[30,1...</td>\n",
       "      <td>[[0,11],[5,7],[10,6],[15,8],[20,2],[25,3],[30,...</td>\n",
       "      <td>[[0,6],[5,2],[10,3],[15,5],[20,3],[25,6],[30,2...</td>\n",
       "      <td>[[0,8],[5,4],[10,2],[15,1],[20,2],[25,4],[30,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.394337</td>\n",
       "      <td>24.708416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[0,1],[20,1],[25,1]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[20,1],[25,1]]</td>\n",
       "      <td>[[0,1]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>18.209458</td>\n",
       "      <td>27.390362</td>\n",
       "      <td>27.410950</td>\n",
       "      <td>26.328913</td>\n",
       "      <td>3.701934</td>\n",
       "      <td>[[0,1501],[5,2401],[10,982],[15,360],[20,145],...</td>\n",
       "      <td>[[0,406],[5,87],[10,16],[15,1],[20,3],[25,3],[...</td>\n",
       "      <td>[[0,1724],[5,763],[10,114],[15,35],[20,8],[25,...</td>\n",
       "      <td>[[0,1884],[5,1491],[10,270],[15,45],[20,11],[2...</td>\n",
       "      <td>[[0,1381],[5,658],[10,129],[15,31],[20,9],[25,...</td>\n",
       "      <td>[[0,316],[5,175],[10,72],[15,50],[20,30],[25,1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         degrees_tilt_n  degrees_tilt_e  degrees_tilt_s  degrees_tilt_w  \\\n",
       "zipcode                                                                   \n",
       "1001          18.057999       26.270523       27.476409       25.391170   \n",
       "1002          17.444525       25.881517       28.781245       26.197519   \n",
       "1003          17.607019       24.261329       31.431343       28.438918   \n",
       "1007                NaN             NaN       23.394337       24.708416   \n",
       "1013          18.209458       27.390362       27.410950       26.328913   \n",
       "\n",
       "         degrees_tilt_f                       install_size_kw_buckets_json  \\\n",
       "zipcode                                                                      \n",
       "1001           2.931321  [[0,1134],[5,1720],[10,774],[15,334],[20,136],...   \n",
       "1002           2.940489  [[0,550],[5,552],[10,265],[15,146],[20,95],[25...   \n",
       "1003           1.980439  [[0,5],[5,4],[10,2],[15,6],[20,2],[25,4],[30,1...   \n",
       "1007                NaN                              [[0,1],[20,1],[25,1]]   \n",
       "1013           3.701934  [[0,1501],[5,2401],[10,982],[15,360],[20,145],...   \n",
       "\n",
       "                            install_size_kw_buckets_n_json  \\\n",
       "zipcode                                                      \n",
       "1001     [[0,283],[5,51],[10,12],[15,4],[20,3],[25,3],[...   \n",
       "1002     [[0,123],[5,33],[10,10],[15,9],[20,3],[25,5],[...   \n",
       "1003      [[0,4],[5,2],[15,1],[25,1],[35,1],[40,1],[45,1]]   \n",
       "1007                                                    []   \n",
       "1013     [[0,406],[5,87],[10,16],[15,1],[20,3],[25,3],[...   \n",
       "\n",
       "                            install_size_kw_buckets_e_json  \\\n",
       "zipcode                                                      \n",
       "1001     [[0,1200],[5,597],[10,163],[15,44],[20,28],[25...   \n",
       "1002     [[0,463],[5,201],[10,62],[15,23],[20,19],[25,1...   \n",
       "1003     [[0,8],[5,8],[10,6],[15,6],[20,2],[25,1],[30,1...   \n",
       "1007                                                    []   \n",
       "1013     [[0,1724],[5,763],[10,114],[15,35],[20,8],[25,...   \n",
       "\n",
       "                            install_size_kw_buckets_s_json  \\\n",
       "zipcode                                                      \n",
       "1001     [[0,1389],[5,1195],[10,243],[15,45],[20,32],[2...   \n",
       "1002     [[0,562],[5,336],[10,134],[15,62],[20,34],[25,...   \n",
       "1003     [[0,11],[5,7],[10,6],[15,8],[20,2],[25,3],[30,...   \n",
       "1007                                       [[20,1],[25,1]]   \n",
       "1013     [[0,1884],[5,1491],[10,270],[15,45],[20,11],[2...   \n",
       "\n",
       "                            install_size_kw_buckets_w_json  \\\n",
       "zipcode                                                      \n",
       "1001     [[0,1045],[5,521],[10,142],[15,36],[20,30],[25...   \n",
       "1002     [[0,483],[5,206],[10,75],[15,40],[20,22],[25,1...   \n",
       "1003     [[0,6],[5,2],[10,3],[15,5],[20,3],[25,6],[30,2...   \n",
       "1007                                               [[0,1]]   \n",
       "1013     [[0,1381],[5,658],[10,129],[15,31],[20,9],[25,...   \n",
       "\n",
       "                            install_size_kw_buckets_f_json  \n",
       "zipcode                                                     \n",
       "1001     [[0,212],[5,77],[10,33],[15,25],[20,19],[25,15...  \n",
       "1002     [[0,117],[5,51],[10,16],[15,12],[20,16],[25,17...  \n",
       "1003     [[0,8],[5,4],[10,2],[15,1],[20,2],[25,4],[30,2...  \n",
       "1007                                                    []  \n",
       "1013     [[0,316],[5,175],[10,72],[15,50],[20,30],[25,1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tilt_size_buckets = pd.read_csv(\"sunroof_data/average_tilt_and_install_size_kw_buckets.csv\")\n",
    "tilt_size_buckets['zipcode'] = tilt_size_buckets['zipcode'].astype(str)\n",
    "tilt_size_buckets = tilt_size_buckets.set_index('zipcode')\n",
    "tilt_size_buckets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# info should describe the data (e.g. tilted roof, flat roof)\n",
    "def create_hourly_csv(df, year, info):\n",
    "    if info != '':\n",
    "        info = '_' + info\n",
    "    if not os.path.isfile('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info)):\n",
    "        df.to_csv('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info))\n",
    "    else:\n",
    "        df.to_csv('csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info), mode='a', header=False)\n",
    "    print(\"Saved hourly csv\")\n",
    "    \n",
    "def create_yearly_csv(df, year, info):\n",
    "    if info != '':\n",
    "        info = '_' + info\n",
    "#     if not os.path.isfile('csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info)):\n",
    "    df.to_csv('csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info))\n",
    "    print(\"Saved yearly csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_tables():\n",
    "    interval = '60'\n",
    "    if description != '':\n",
    "        info = '_' + description\n",
    "    path_to_yearly = 'csvs/agg_years/yearly{year}{info}.csv'.format(year = year, info = info)\n",
    "    path_to_hourly = 'csvs/agg_years/hourly{year}{info}.csv'.format(year = year, info = info)\n",
    "\n",
    "    hourly_df = pd.DataFrame(index = pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "    hourly_df.columns.name = None\n",
    "    hourly_df_zipcodes = []\n",
    "    if os.path.isfile(path_to_yearly) and os.path.isfile(path_to_hourly):\n",
    "        print(\"Reading existing files for {year}{info}\".format(year = year, info = info))\n",
    "        yearly_generations = pd.read_csv(path_to_yearly).set_index('region_name')['generations']\n",
    "        yearly_generations.index = yearly_generations.index.astype(str) # zipcode indices are interpreted as int, but we want str\n",
    "        hourly_df_zipcodes = pd.read_csv(path_to_hourly, index_col=0).index.astype(str)\n",
    "        \n",
    "    else:\n",
    "        print(\"New tables will be generated\")\n",
    "        yearly_generations = pd.Series(np.nan, index = latlon['region_name'])\n",
    "        \n",
    "    return yearly_generations, hourly_df, hourly_df_zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_sam(year, direction):\n",
    "\n",
    "    interval = '60'\n",
    "\n",
    "    # Run weather data through SAM\n",
    "    for index, row in latlon.iterrows():\n",
    "        if row['region_name'] not in tilt_size_buckets.index:\n",
    "            print(\"No tilt data available.\")\n",
    "            continue\n",
    "        else:\n",
    "            tilt = 15\n",
    "            gcr = 0.7\n",
    "        if not np.isnan(yearly_generations.loc[row['region_name']]) and row['region_name'] in existing_zipcodes_hourly:\n",
    "            continue\n",
    "\n",
    "        if os.path.isfile('{path}{year}/{region}_{state}.csv'.format(path=path_to_csv, year=year, region=row['region_name'], state=row['state_name'])):\n",
    "            data = pd.read_csv('{path}{year}/{region}_{state}.csv'.format(path=path_to_csv, year=year, region=row['region_name'], state=row['state_name']))\n",
    "        else:\n",
    "            print(\"No weather data for \" + row['region_name'])\n",
    "            continue\n",
    "\n",
    "        lat = row['lat_avg']\n",
    "        lon = row['lng_avg']\n",
    "        capacity = row['capacity']\n",
    "        metadata = data.iloc[0:1, :]\n",
    "\n",
    "        timezone = metadata['Time Zone'].values[0]\n",
    "        elevation = metadata['Elevation'].values[0]\n",
    "\n",
    "        # omit metadata at the top (hence the 2:)\n",
    "        loc_data = data.iloc[:,:]\n",
    "        loc_data.columns = loc_data.iloc[1] # reassign column names to the ones in the first row of the old table\n",
    "        loc_data = loc_data.iloc[2:, :]\n",
    "        loc_data = loc_data.set_index(pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "        loc_data = loc_data.dropna(axis = 1, how='all')\n",
    "        loc_data[['DNI','DHI', 'Wind Speed', 'Temperature']] = loc_data[['DNI','DHI', 'Wind Speed', 'Temperature']].apply(pd.to_numeric)\n",
    "\n",
    "        wfd = ssc.data_create()\n",
    "        ssc.data_set_number(wfd, 'lat', lat)\n",
    "        ssc.data_set_number(wfd, 'lon', lon)\n",
    "        ssc.data_set_number(wfd, 'tz', float(timezone))\n",
    "        ssc.data_set_number(wfd, 'elev', float(elevation))\n",
    "        ssc.data_set_array(wfd, 'year', loc_data.index.year)\n",
    "        ssc.data_set_array(wfd, 'month', loc_data.index.month)\n",
    "        ssc.data_set_array(wfd, 'day', loc_data.index.day)\n",
    "        ssc.data_set_array(wfd, 'hour', loc_data.index.hour)\n",
    "        ssc.data_set_array(wfd, 'minute', loc_data.index.minute)\n",
    "        ssc.data_set_array(wfd, 'dn', loc_data['DNI'])\n",
    "        ssc.data_set_array(wfd, 'df', loc_data['DHI'])\n",
    "        ssc.data_set_array(wfd, 'wspd', loc_data['Wind Speed'])\n",
    "        ssc.data_set_array(wfd, 'tdry', loc_data['Temperature'])\n",
    "\n",
    "        # Create SAM compliant object  \n",
    "        dat = ssc.data_create()\n",
    "        ssc.data_set_table(dat, 'solar_resource_data', wfd)\n",
    "        ssc.data_free(wfd)\n",
    "\n",
    "        # Specify the system Configuration\n",
    "        # Set system capacity in MW\n",
    "        system_capacity = capacity\n",
    "        ssc.data_set_number(dat, 'system_capacity', system_capacity)\n",
    "        # Set DC/AC ratio (or power ratio). See https://sam.nrel.gov/sites/default/files/content/virtual_conf_july_2013/07-sam-virtual-conference-2013-woodcock.pdf\n",
    "        ssc.data_set_number(dat, 'dc_ac_ratio', 1.15)\n",
    "        # Set tilt of system in degrees\n",
    "        # For Google data, roof segments are considered Flat for roofs with a tilt of less than 10%\n",
    "        ssc.data_set_number(dat, 'tilt', tilt) ####tilt\n",
    "        # Set azimuth angle (in degrees) from north (0 degrees)\n",
    "        ssc.data_set_number(dat, 'azimuth', 180)\n",
    "        # Set the inverter efficency\n",
    "        ssc.data_set_number(dat, 'inv_eff', 96)\n",
    "        # Set the system losses, in percent\n",
    "        ssc.data_set_number(dat, 'losses', 14.0757)\n",
    "        # Specify fixed tilt system (0=Fixed, 1=Fixed Roof, 2=1 Axis Tracker, 3=Backtracted, 4=2 Axis Tracker)\n",
    "        ssc.data_set_number(dat, 'array_type', 0)\n",
    "        # Set ground coverage ratio (PACKING DENSITY)\n",
    "        ssc.data_set_number(dat, 'gcr', gcr)\n",
    "#         ssc.data_set_number(dat, 'gcr', (np.cos(np.radians(lat)))**2) ####Packing Density\n",
    "        # Set constant loss adjustment\n",
    "        ssc.data_set_number(dat, 'adjust:constant', 0)\n",
    "\n",
    "        # execute and put generation results back into dataframe\n",
    "        mod = ssc.module_create('pvwattsv5')\n",
    "        ssc.module_exec(mod, dat)\n",
    "        loc_data['generation'] = np.array(ssc.data_get_array(dat, 'gen'))\n",
    "        hourly_df.loc[:, row['region_name']] = loc_data['generation'] # column of generation data from SAM model\n",
    "        # free the memory\n",
    "        ssc.data_free(dat)\n",
    "        ssc.module_free(mod)\n",
    "        sys.stdout.write('\\r{0}. {1}: {2}'.format(index, row['region_name'], loc_data['generation'].sum()))\n",
    "        sys.stdout.flush()\n",
    "        yearly_generations[row['region_name']] = loc_data['generation'].sum()*1000\n",
    "        \n",
    "        if (index + 1) % 1000 == 0:\n",
    "            return index + 1\n",
    "#             output_yearly = latlon.set_index('region_name')\n",
    "#             output_yearly['generations'] = yearly_generations\n",
    "#             print()\n",
    "#             create_hourly_csv(hourly_df.T, year, description)\n",
    "#             create_yearly_csv(output_yearly, year, description)\n",
    "#             hourly_df = pd.DataFrame(index = pd.date_range('1/1/{yr}'.format(yr=year), freq=interval+'Min', periods=525600/int(interval)))\n",
    "            \n",
    "    return len(latlon)\n",
    "    # latlon['generations'] = yearly_generations\n",
    "    # latlon['error codes'] = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing files for 2012_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No weather data for 99258\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "Saved hourly csv\n",
      "Saved yearly csv\n",
      "Reading existing files for 2013_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "Saved hourly csv\n",
      "Saved yearly csv\n",
      "Reading existing files for 2014_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "Saved hourly csv\n",
      "Saved yearly csv\n",
      "Reading existing files for 2015_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "6999. 32908: 13222.446802854072Saved hourly csv\n",
      "Saved yearly csv\n",
      "Reading existing files for 2015_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "7598. 33896: 10802.985485506244No tilt data available.\n",
      "7602. 46221: 47620.657815411692No tilt data available.\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "7637. 46260: 46350.536652412734No tilt data available.\n",
      "7650. 46231: 36388.464753226267No tilt data available.\n",
      "7652. 46237: 49378.99362484738No tilt data available.\n",
      "7657. 33914: 43811.89571056748No tilt data available.\n",
      "7661. 46235: 35969.794316501415No tilt data available.\n",
      "7858. 95519: 25240.239096644325\n",
      "Length mismatch: Expected axis has 6152 elements, new values have 8760 elements\n",
      "Closing. Saving current progress...\n",
      "Saved hourly csv\n",
      "Saved yearly csv\n",
      "Saved\n",
      "Reading existing files for 2016_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "2999. 30813: 55745.073926511224Saved hourly csv\n",
      "Saved yearly csv\n",
      "Reading existing files for 2016_flat_tilt_nrel\n",
      "No tilt data available.\n",
      "No tilt data available.\n",
      "3563. 32221: 52231.291176141705\n",
      "Length mismatch: Expected axis has 7467 elements, new values have 8760 elements\n",
      "Closing. Saving current progress...\n",
      "Saved hourly csv\n",
      "Saved yearly csv\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to start the program\n",
    "for year in [2016]:\n",
    "    for direction in ['n', 'w', 'e', 's']\n",
    "        try:\n",
    "            num_finished = 0\n",
    "            while num_finished < len(zipcodes):\n",
    "                yearly_generations, hourly_df, existing_zipcodes_hourly = instantiate_tables()\n",
    "                num_finished = run_sam(year)\n",
    "                output_yearly = latlon.set_index('region_name')\n",
    "                output_yearly['generations'] = yearly_generations\n",
    "                create_hourly_csv(hourly_df.T, year, description)\n",
    "                create_yearly_csv(output_yearly, year, description)\n",
    "        except (KeyboardInterrupt, Exception) as e:\n",
    "            print()\n",
    "            print(e)\n",
    "            print(\"Closing. Saving current progress...\")\n",
    "            output_yearly = latlon.set_index('region_name')\n",
    "            output_yearly['generations'] = yearly_generations\n",
    "\n",
    "\n",
    "            create_hourly_csv(hourly_df.T, year, description)\n",
    "            create_yearly_csv(output_yearly, year, description)\n",
    "            print(\"Saved\")\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
